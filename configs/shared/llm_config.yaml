# configs/shared/llm_config.yaml (C·∫¨P NH·∫¨T HO√ÄN CH·ªàNH)

# C·∫•u h√¨nh ch√≠nh ƒë∆∞·ª£c s·ª≠ d·ª•ng b·ªüi LLMFactory (LLMServiceConfig)
LLM_SERVICE:
  # Chi ph√≠ cao, ch·∫•t l∆∞·ª£ng cao, c√≥ Retry/Fallback (Primary LLM)
  primary:
    type: "openai"
    # üö® C·∫¨P NH·∫¨T: C√°c tham s·ªë n·∫±m tr·ª±c ti·∫øp ·ªü ƒë√¢y, kh√¥ng l·ªìng trong 'config'
    model_name: "gpt-4o"
    api_key_secret_name: "OPENAI_API_KEY"
    temperature: 0.7
    max_tokens: 1500
    max_retries: 5 # C√≥ th·ªÉ ƒë∆∞·ª£c chuy·ªÉn v√†o logic LLM Wrapper
    retry_delay_seconds: 4 # C√≥ th·ªÉ ƒë∆∞·ª£c chuy·ªÉn v√†o logic LLM Wrapper

  # Chi ph√≠ th·∫•p, d√πng khi Primary th·∫•t b·∫°i (Fallback LLM)
  fallback:
    type: "huggingface"
    # üö® C·∫¨P NH·∫¨T: C√°c tham s·ªë n·∫±m tr·ª±c ti·∫øp ·ªü ƒë√¢y
    model_name: "llama-3-8b-instruct"
    model_path: "/models/llama-3-8b"
    device: "cuda"

# C·∫•u h√¨nh m√¥ h√¨nh Embedding (th∆∞·ªùng l√† m√¥ h√¨nh kh√°c)
EMBEDDING_MODEL:
  type: "openai"
  model_name: "text-embedding-3-small"
  # üö® B·ªî SUNG: C·∫ßn API key n·∫øu embedding model kh√¥ng d√πng chung secret
  api_key_secret_name: "OPENAI_EMBEDDING_API_KEY"
