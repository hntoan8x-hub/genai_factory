# ----------------------------------------------------
# ðŸ”¹ 2.1 DEPLOYMENT: Inference API (Role: INFERENCE)
# ----------------------------------------------------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: genai-assistant-inference
  labels:
    app: genai-assistant
    role: inference
spec:
  replicas: 2 # Khá»Ÿi táº¡o 2 replicas ban Ä‘áº§u
  selector:
    matchLabels:
      app: genai-assistant
  template:
    metadata:
      labels:
        app: genai-assistant
    spec:
      securityContext:
        # HARDENING: YÃªu cáº§u cháº¡y dÆ°á»›i non-root user (appuser)
        runAsUser: 1000 # Giáº£ sá»­ appuser cÃ³ UID 1000
        fsGroup: 1000
      containers:
        - name: assistant-api
          # Sá»­ dá»¥ng Image tá»« inference.Dockerfile
          image: your-registry/genai-factory:inference-v1.0
          ports:
            - containerPort: 8000

          # HARDENING: Resource Limits (CRITICAL for cost control & stability)
          resources:
            limits:
              cpu: "1500m" # 1.5 core
              memory: "4Gi"
            requests:
              cpu: "500m"
              memory: "2Gi"

          # HARDENING: TiÃªm Secrets vÃ  Configs
          envFrom:
            - secretRef:
                name: genai-factory-secrets
            - configMapRef:
                name: genai-factory-configs

          # Liveness/Readiness Probe (Kiá»ƒm tra Healthcheck)
          readinessProbe:
            httpGet:
              path: /health # Giáº£ Ä‘á»‹nh API cÃ³ endpoint /health
              port: 8000
            initialDelaySeconds: 10
            periodSeconds: 5

          # Khá»Ÿi Ä‘á»™ng (Lá»‡nh CMD tá»« inference.Dockerfile)
          # CMD ["gunicorn", "api_service.app:app", ...]

---
# ----------------------------------------------------
# ðŸ”¹ 2.2 SERVICE & HPA (HorizontalPodAutoscaler)
# ----------------------------------------------------
apiVersion: v1
kind: Service
metadata:
  name: genai-assistant-service
spec:
  selector:
    app: genai-assistant
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
  type: LoadBalancer

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: assistant-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: genai-assistant-inference
  minReplicas: 2
  maxReplicas: 10 # HARDENING: Giá»›i háº¡n tá»‘i Ä‘a 10 replicas
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70 # Tá»± Ä‘á»™ng scale khi CPU > 70%
