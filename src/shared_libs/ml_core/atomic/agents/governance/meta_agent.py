# shared_libs/atomic/agents/governance/meta_agent.py

from shared_libs.base.base_agent import BaseAgent
from shared_libs.base.base_llm import BaseLLM
from shared_libs.utils.exceptions import GenAIFactoryError
from typing import Dict, Any, Optional
import asyncio
import json

class MetaAgent(BaseAgent):
    """
    Agent chuyÃªn biá»‡t giÃ¡m sÃ¡t hiá»‡u suáº¥t (latency, cost) vÃ  Ä‘á» xuáº¥t/thá»±c hiá»‡n 
    tÃ¹y chá»‰nh tham sá»‘ (config/hyperparameters) cho cÃ¡c Agents khÃ¡c trong há»‡ thá»‘ng.
    Vai trÃ²: Táº§ng 3 (Oversight) - Tá»‘i Æ°u hÃ³a Tá»± Ä‘á»™ng vÃ  FinOps.
    """

    @property
    def name(self) -> str:
        return "meta_optimization_agent"

    @property
    def description(self) -> str:
        return "Monitors the performance metrics (latency, token usage, error rates) of all Worker Agents and automatically recommends configuration adjustments (max_loops, temperature, LLM model) for cost and speed optimization. Responds ONLY with JSON."

    def __init__(self, llm: BaseLLM):
        """Khá»Ÿi táº¡o MetaAgent chá»‰ vá»›i LLM."""
        self.llm = llm

    # --- Core Optimization Method (Asynchronous) ---
    async def async_analyze_and_propose_optimization(self, agent_metrics: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """
        PhÃ¢n tÃ­ch metrics cá»§a Agent vÃ  Ä‘á» xuáº¥t tÃ¹y chá»‰nh cáº¥u hÃ¬nh.
        
        Args:
            agent_metrics (Dict): Metrics hiá»‡u suáº¥t hiá»‡n táº¡i (vÃ­ dá»¥: {'risk_manager': {'avg_cost': 0.50, 'error_rate': 0.1, 'avg_latency': 5.2}}).

        Returns:
            Dict: Äá» xuáº¥t cáº¥u hÃ¬nh má»›i (vÃ­ dá»¥: {'risk_manager': {'max_loops': 8, 'temperature': 0.5}}).
        """
        
        metrics_summary = "\n".join([f"- Agent {name}: {json.dumps(metrics)}" for name, metrics in agent_metrics.items()])
        
        system_message = (
            "You are the Meta-Optimization Engine. Analyze the 'Agent Performance Metrics' below. "
            "Your goal is to propose adjustments to agent configurations (e.g., max_loops, temperature, LLM model) "
            "to minimize cost, reduce latency, or lower the error rate. "
            "Respond ONLY with a valid JSON dictionary where keys are agent names and values are their new configurations."
        )

        prompt = f"""
        AGENT PERFORMANCE METRICS:
        ---
        {metrics_summary}
        ---
        
        PROPOSED OPTIMIZATION (JSON format only):
        """
        
        try:
            # LLM phÃ¢n tÃ­ch vÃ  tráº£ vá» JSON Ä‘á» xuáº¥t
            optimization_json_str = await self.llm.async_generate(
                system_message + "\n\n" + prompt,
                temperature=0.0  # Pháº£i lÃ  deterministic Ä‘á»ƒ táº¡o ra JSON há»£p lá»‡
            )
            
            # ðŸš¨ HARDENING: Xá»­ lÃ½ lá»—i JSON Parsing
            try:
                # TÃ¬m vÃ  lÃ m sáº¡ch JSON Ä‘á»ƒ trÃ¡nh LLM thÃªm vÄƒn báº£n ngoÃ i lá»
                # CÃ³ thá»ƒ dÃ¹ng regex Ä‘á»ƒ trÃ­ch xuáº¥t { ... }
                # Tuy nhiÃªn, ta giáº£ Ä‘á»‹nh LLM tuÃ¢n thá»§ yÃªu cáº§u "Respond ONLY with a valid JSON dictionary"
                return json.loads(optimization_json_str)
            except json.JSONDecodeError as e:
                print(f"Meta Agent: LLM returned invalid JSON. Error: {e}")
                return {} # Tráº£ vá» dict rá»—ng náº¿u lá»—i parse

        except Exception as e:
            raise GenAIFactoryError(f"Meta Agent failed to execute optimization task: {e}")

    # --- BaseAgent Abstract Methods (Cháº·n vÃ²ng láº·p) ---
    def loop(self, user_input: str, max_steps: int = 10, timeout: Optional[int] = None) -> str:
        raise NotImplementedError("Meta Agent is for optimization tasks, not standard loop execution.")
    
    async def async_loop(self, user_input: str, max_steps: int = 10, timeout: Optional[int] = None) -> str:
        raise NotImplementedError("Meta Agent is for optimization tasks, not standard loop execution.")

    # ... (TÆ°Æ¡ng tá»± cho plan, act, observe)